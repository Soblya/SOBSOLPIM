Набор слоёв keras

```
mdl = keras.Sequential()
```

Входной слой keras, состоит из искуственных нейронов, позволяет передать начальные данные в последующие слои НС

```
mdl.add(InputLayer(input_shape=(150,150,3)))
```

В конвуляционном слое происходит определение свойств(каких -- точно не известно, выявляется корреляция между значениями), которые будут в дальнейшем классифицироваться плотосвязным слоем.
Конвуляционный(свёрточный) слой(фильтр). Идентифицирует некие свойства вводных данных, рассматривает матрицы 3*3. Значение 32 обозначает, что на выходе фильтра будет 32 параметра.
Активация срабатывает по алгоритму relu: возвращает 0, если принимает отрицательный аргумент иначе возвращает само число. Padding: указывает каким образом будут возвращаться данные:
в случае same -- поместит вывод в центре матрицы из нулей. valid -- вернёт без изменений.

```
mdl.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'))
```

Слой для понижения ранга матрицы с усреднением значений.

```
mdl.add(MaxPool2D())
```

Ещё один конвуляционный слой, так же как и предыдущий идентифицирует некие свойства приходящих в него данных, в данном случае рассматривая более общую картину.

```
mdl.add(Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'))
mdl.add(MaxPool2D())
```

Данный слой трансформирует многомерный вектор в последовательность одномерных.
```
mdl.add(Flatten())
```

Плотно связный слой, имеющий 128 нейронов. Осуществляет классификацию ранее идентифицированных свойств
```
mdl.add(Dense(128, activation='relu'))
```
Слой пакетной нормализации: нормализует данные, поступающие в следующий слой, это позволяет гарантировать, что функции активации создаются с одинаковым распределением. 
```
mdl.add(BatchNormalization())
```
Слой отброса нейронов, для предотвращения переобучения, случайным образом устраняет 30% соединений между слоями
```
mdl.add(Dropout(rate=0.3))
```

Плотно связный слой, имеющий 64 нейронов.
```
mdl.add(Dense(64, activation='relu'))
```
Слой пакетной нормализации: нормализует данные, поступающие в следующий слой, это позволяет гарантировать, что функции активации создаются с одинаковым распределением. 
```
mdl.add(BatchNormalization())
```
Слой отброса нейронов, для предотвращения переобучения, случайным образом устраняет 30% соединений между слоями
```
mdl.add(Dropout(rate=0.3))
```

Плотно связный слой, имеющий 1 нейрон. Осуществляет финальную классификацию признаков, активация происходит функцией sigmoid, она возвращает значение от 0 до 1: 0 болезнь не обнаружена, 1 болезнь обнаружена
```
mdl.add(Dense(1, activation='sigmoid'))
```

Оптимизитор -- это функция, которая автоматически настраивает веса в сети, минимизируя потери.
```
mdl.compile(optimizer=Adam(0.001), loss=BinaryCrossentropy(), metrics=['accuracy', 'MeanSquaredError', 'FalseNegatives']) 
```
Метрики: точность предсказания, ложноположительные результаты